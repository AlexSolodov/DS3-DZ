{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# все любят картиночки:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# docker контейнер уже должен содержать в себе скачанные данные\n",
    "# скачаны отсюда: https://grouplens.org/datasets/movielens/\n",
    "DATA_DIR = \"/data/ml-latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.txt\t   genome-tags.csv  movies.csv\t tags.csv     tf_idf.parquet\r\n",
      "genome-scores.csv  links.csv\t    ratings.csv  tf_idf.json\r\n"
     ]
    }
   ],
   "source": [
    "# смотрим, какие файлы у нас есть\n",
    "!ls {DATA_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId,movieId,rating,timestamp\r",
      "\r\n",
      "1,110,1.0,1425941529\r",
      "\r\n",
      "1,147,4.5,1425942435\r",
      "\r\n",
      "1,858,5.0,1425941523\r",
      "\r\n",
      "1,1221,5.0,1425941546\r",
      "\r\n",
      "1,1246,5.0,1425941556\r",
      "\r\n",
      "1,1968,4.0,1425942148\r",
      "\r\n",
      "1,2762,4.5,1425941300\r",
      "\r\n",
      "1,2918,5.0,1425941593\r",
      "\r\n",
      "1,2959,4.0,1425941601\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# обратим внимание на файл с оценками\n",
    "!head {DATA_DIR}/ratings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# для подготовки данных будем использвоать Apache Spark\n",
    "# (популярный фреймворк распределённых вычислений)\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    # если виртуальной машине нельзя добавить памяти, можно использовать меньше\n",
    "    .config(\"spark.driver.memory\", \"8g\")\n",
    "    # можно явно количество ядер, которые будет использовать Spark\n",
    "    # либо поставить звёздочку для всех доступных виртуальной машине\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# считываем данные из CSV\n",
    "# и преобразуем время проставления оценки из целого числа в дату со временем\n",
    "import os\n",
    "import pyspark.sql.functions as sql_func\n",
    "\n",
    "ratings = (\n",
    "    spark\n",
    "    .read\n",
    "    .csv(\n",
    "        os.path.join(DATA_DIR, \"ratings.csv\"),\n",
    "        header=True,\n",
    "        inferSchema=True\n",
    "    )\n",
    "    # если используется меньше памяти,\n",
    "    # то здесь можно взять не все данные, а а небольшую выборку\n",
    "    # даже при fraction=0.01 качественная картина не меняется\n",
    "    .sample(withReplacement=False, fraction=0.1, seed=0)\n",
    "    .withColumn(\"rating_datetime\", sql_func.from_unixtime(\"timestamp\"))\n",
    "    .drop(\"timestamp\")\n",
    "    .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              tf_idf|\n",
      "+-------+--------------------+--------------------+\n",
      "|     35|   Carrington (1995)|(1024,[8,74,189,2...|\n",
      "|    503| New Age, The (1994)|(1024,[434,769,82...|\n",
      "|    583|Dear Diary (Caro ...|(1024,[434,741,84...|\n",
      "|    594|Snow White and th...|(1024,[29,52,60,8...|\n",
      "|    610|  Heavy Metal (1981)|(1024,[32,93,112,...|\n",
      "|    614|       Loaded (1994)|(1024,[263,434],[...|\n",
      "|    761| Phantom, The (1996)|(1024,[43,169,196...|\n",
      "|    880|Island of Dr. Mor...|(1024,[44,81,219,...|\n",
      "|   1369|I Can't Sleep (J'...|(1024,[263,434],[...|\n",
      "|   1519|Broken English (1...|(1024,[434,829],[...|\n",
      "|   1589|     Cop Land (1997)|(1024,[37,61,164,...|\n",
      "|   1815|         Eden (1997)|(1024,[434,829],[...|\n",
      "|   1881|Quest for Camelot...|(1024,[57,165,337...|\n",
      "|   2080|Lady and the Tram...|(1024,[29,37,83,1...|\n",
      "|   2324|Life Is Beautiful...|(1024,[3,31,32,45...|\n",
      "|   2444|24 7: Twenty Four...|(1024,[122,221,43...|\n",
      "|   2445|At First Sight (1...|(1024,[177,208,34...|\n",
      "|   2649|Son of Frankenste...|(1024,[40,78,208,...|\n",
      "|   2915|Risky Business (1...|(1024,[9,65,76,10...|\n",
      "|   3065|Nothing to Lose (...|(1024,[434,829],[...|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pyspark.sql.functions as sql_func\n",
    "\n",
    "# поскольку в Parquet схема данных хранится внутри самого файла, читать их очень просто\n",
    "tf_idf = spark.read.parquet(os.path.join(DATA_DIR, \"tf_idf.parquet\")).cache()\n",
    "tf_idf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "всего пользователей: 229897\n",
      "всего фильмов: 26166\n",
      "всего оценок: 2599745\n"
     ]
    }
   ],
   "source": [
    "# оцениваем размеры данных\n",
    "print(\"всего пользователей:\", ratings.select(\"userId\").distinct().count())\n",
    "print(\"всего фильмов:\", ratings.select(\"movieId\").distinct().count())\n",
    "print(\"всего оценок:\", ratings.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "средняя оценка: 3.5280369805500156\n"
     ]
    }
   ],
   "source": [
    "# достаточно хорошим baseline является предсказывать среднюю оценку\n",
    "mean_rating = ratings.agg(sql_func.avg(\"rating\")).first()[0]\n",
    "print(\"средняя оценка:\", mean_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# функция, с помощью которой мы будем вычислять RMSE на обучающей выборке\n",
    "from pyspark.sql import DataFrame\n",
    "import numpy as np\n",
    "\n",
    "def simple_evaluate(predictions_df: DataFrame) -> float:\n",
    "    return np.sqrt(\n",
    "            ratings\n",
    "            .join(\n",
    "                predictions_df,\n",
    "                [\"movieId\", \"userId\"]\n",
    "            ).select(\n",
    "                sql_func.pow(\n",
    "                    ratings.rating - predictions_df.prediction,\n",
    "                    2\n",
    "                ).alias(\"squared_error\")\n",
    "            )\n",
    "            .agg(sql_func.avg(\"squared_error\"))\n",
    "            .first()[0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ошибка предсказания: 1.065588580528197\n"
     ]
    }
   ],
   "source": [
    "# рекомендуем любому пользователю любой фильм случайно\n",
    "mean_predictions = ratings.withColumn(\"prediction\", sql_func.lit(mean_rating))\n",
    "print(\"ошибка предсказания:\", simple_evaluate(mean_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# посмотрим на распределение средних оценок разных фильмов\n",
    "movie_ratings = (\n",
    "    ratings\n",
    "    .groupBy(\"movieId\")\n",
    "    .agg(sql_func.avg(\"rating\").alias(\"avg_movie_rating\"))\n",
    "    .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# у разных пользователей разные распределения оценок\n",
    "# кто-то более придирчив, а кто-то всем ставит пятёрки\n",
    "user_ratings = (\n",
    "    ratings\n",
    "    .groupBy(\"userId\")\n",
    "    .agg(sql_func.avg(\"rating\").alias(\"avg_user_rating\"))\n",
    "    .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# а можем и не полусумму, а подобрать коэффициенты\n",
    "# с помощью линейной регрессии\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "train = (\n",
    "    VectorAssembler(\n",
    "        inputCols = [\"avg_movie_rating\", \"avg_user_rating\", \"tf_idf\"],\n",
    "        outputCol = \"features\"\n",
    "    ).transform(\n",
    "        ratings\n",
    "        .join(movie_ratings, \"movieId\")\n",
    "        .join(user_ratings, \"userId\")\n",
    "        .join(tf_idf, \"movieId\")\n",
    "    )\n",
    "    .withColumnRenamed(\"rating\", \"label\")\n",
    "    .select(\"movieId\", \"userId\", \"label\", \"features\")\n",
    "    .cache()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(movieId=91500, userId=1, label=2.5, features=SparseVector(1026, {0: 3.5849, 1: 2.5, 20: 139.6376, 37: 22.5082, 39: 14.5658, 44: 14.0427, 47: 4.7746, 48: 30.618, 63: 55.395, 66: 5.5972, 72: 5.9623, 78: 58.3801, 89: 5.4247, 107: 5.0259, 110: 304.7821, 122: 5.46, 124: 4.3874, 130: 5.2441, 135: 176.1395, 182: 10.1681, 184: 5.7494, 202: 10.4964, 205: 10.92, 210: 6.35, 236: 6.2903, 241: 4.9741, 247: 10.1681, 254: 12.424, 261: 7.9498, 265: 35.8053, 276: 53.0145, 287: 5.5019, 300: 68.2947, 301: 5.016, 305: 123.9866, 307: 5.1272, 323: 5.3214, 327: 11.9246, 329: 28.8846, 330: 4.205, 345: 1.9462, 356: 5.5568, 358: 4.6039, 361: 61.1301, 370: 62.9784, 385: 23.6087, 389: 14.0981, 394: 5.7091, 396: 11.8094, 404: 74.1915, 406: 4.8386, 411: 145.9017, 421: 5.2734, 423: 126.515, 436: 9.1098, 439: 3.3299, 440: 4.8114, 442: 105.4234, 447: 87.1953, 450: 4.1156, 461: 19.7235, 494: 100.439, 497: 135.0977, 507: 8.4395, 520: 5.0798, 531: 10.82, 537: 4.5888, 559: 11.2785, 566: 5.2863, 590: 5.5797, 591: 6.0145, 593: 5.3577, 598: 5.0259, 607: 11.0912, 610: 10.6879, 613: 5.6478, 620: 9.7161, 632: 128.3644, 637: 5.7157, 643: 5.2196, 646: 11.2785, 648: 64.0891, 660: 10.972, 689: 10.5215, 690: 11.4851, 714: 9.8022, 730: 6.2444, 741: 6.3142, 751: 10.8325, 780: 10.7528, 790: 4.6215, 792: 23.9195, 794: 4.3228, 813: 17.1671, 826: 4.7217, 840: 5.2777, 857: 45.4142, 859: 5.18, 880: 5.4966, 883: 10.1822, 888: 3.9611, 901: 4.8034, 916: 2.9046, 919: 14.1359, 925: 19.5578, 930: 5.8502, 936: 5.3348, 940: 5.0029, 967: 15.1585, 977: 5.3764, 983: 60.1734, 1000: 27.891, 1013: 5.9881}))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ошибка предсказания: 0.8347906878605614\n"
     ]
    }
   ],
   "source": [
    "linear_model = LinearRegression().fit(train)\n",
    "stacked_prediction = (\n",
    "    ratings\n",
    "    .join(linear_model.transform(train), [\"movieId\", \"userId\"])\n",
    "    .select(\"movieId\", \"userId\", \"prediction\")\n",
    ")\n",
    "print(\"ошибка предсказания:\", simple_evaluate(stacked_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[на сколько пользователь оценит фильм] = -2.44 + 0.83 * [средняя оценка этого фильма] + 0.87 * [средняя оценка из поставленных этим пользователем]\n"
     ]
    }
   ],
   "source": [
    "# получаем некоторую формулу для предсказания оценки, которую можно использовать для рекомендаций\n",
    "print(\n",
    "    \"[на сколько пользователь оценит фильм] = {} + {} * [средняя оценка этого фильма] + {} * [средняя оценка из поставленных этим пользователем]\"\n",
    "    .format(\n",
    "        round(linear_model.intercept, 2),\n",
    "        round(linear_model.coefficients[0], 2),\n",
    "        round(linear_model.coefficients[1], 2)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Эта формула является частным случаем рекомендтельной архитектуры, когда мы для заданного пользователя $u$ получаем рекомендации в два этапа:\n",
    "\n",
    "1. составляем список объектов $i$, которые в принципе могут заинтересовать пользователя $u$\n",
    "1. ранжируем этот список объектов по некоторому правилу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "В частности, правило может основываться на присвоении каждому объекту из списка некоторой релевантности как функции от свойств пользователя и самого объекта: $r\\left(u,i\\right)$\n",
    "\n",
    "В простейшем примере, рассмотренном в этой тетради $r\\left(u,i\\right)=ar_i+br_u+c$ - линейная функция от двух переменных:\n",
    "\n",
    "1. $r_i$ - одного свойства объекта (популярности фильма в виде средней оценки) и\n",
    "1. $r_u$ - одного свойства пользователя (\"разборчивости\" в виде среднего от распределения всех оценок в истории этого пользователя)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
